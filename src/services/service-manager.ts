/**
 * ServiceManager - Central orchestrator for all extension services
 *
 * ## üèóÔ∏è Service Architecture Overview
 *
 * The extension uses a dual-mode service architecture to handle different execution contexts:
 *
 * ### üîÑ Service Modes
 *
 * **Main Mode (Offscreen Document)**:
 * - Full service implementations with complete functionality
 * - Real database instance, actual AI model loading
 * - Heavy computation and resource-intensive operations
 * - Acts as the "server" for proxy services
 *
 * **Proxy Mode (UI/Popup)**:
 * - Lightweight proxy implementations
 * - Forward requests to main services via RPC
 * - Minimal resource usage for responsive UI
 * - No direct model/database access
 *
 * ### üìç Context-Specific Service Usage
 *
 * **üñ•Ô∏è Offscreen Document (`public/offscreen.html`)**:
 * ```typescript
 * // Uses MAIN mode - full service implementations
 * await serviceManager.initialize({ proxy: false });
 *
 * // Services have direct access to:
 * - Real PGlite database instance
 * - Loaded AI models (embeddings, LLM)
 * - Full processing capabilities
 * ```
 *
 * **üé® UI/Popup (`popup.html`, `standalone.html`)**:
 * ```typescript
 * // Uses PROXY mode - lightweight proxies
 * await serviceManager.initialize({ proxy: true });
 *
 * // Services forward requests to offscreen:
 * - DatabaseService ‚Üí sends RPC to main database
 * - EmbeddingService ‚Üí forwards to offscreen models
 * - LLMService ‚Üí proxies to main thread
 * ```
 *
 * **üìú Background Script (`src/background.ts`)**:
 * ```typescript
 * // NO SERVICE ACCESS - Background script does not use ServiceManager
 * // Only handles:
 * - Context menu registration
 * - Content script communication
 * - Job enqueueing via background-jobs
 * ```
 *
 * **üìÑ Content Scripts**:
 * ```typescript
 * // NO SERVICE ACCESS - Content scripts do not use ServiceManager
 * // Only handles:
 * - Page data extraction
 * - DOM manipulation
 * - Communication with background script only
 * ```
 *
 * ### üîó Service Communication Flow
 *
 * ```
 * UI (Proxy Services) ‚îÄRPC‚îÄ> Offscreen (Main Services) ‚îÄ> Database/AI Models
 *                                    ‚Üë
 * Background Script ‚îÄjobs‚îÄ> Background Jobs Queue
 *                                    ‚Üë
 * Content Scripts ‚îÄdata‚îÄ> Background Script
 * ```
 *
 * ### üí° Benefits of This Architecture
 *
 * - **Performance**: Heavy operations isolated to offscreen document
 * - **Responsiveness**: UI remains fast with lightweight proxy services
 * - **Resource Management**: Single source of truth for models/database
 * - **Clean Separation**: Each context has well-defined responsibilities
 * - **Type Safety**: Same interfaces for both main and proxy implementations
 */

import { logError, logInfo, logWarn } from "@/utils/logger";
import type { IEmbeddingService } from "@/services/embedding";
import {
	EmbeddingServiceMain,
	EmbeddingServiceProxy,
} from "@/services/embedding";
import type { ILLMService } from "@/services/llm/interfaces/llm-service.interface";
import { LLMServiceProxy, LLMServiceMain } from "@/services/llm";
import { FlowsService } from "./flows";
import { DatabaseMode, DatabaseService } from "./database";

export interface InitializationProgress {
	step: string;
	progress: number; // 0-100
	currentService?: string;
	isComplete: boolean;
}

export class ServiceManager {
	private static instance: ServiceManager;
	private initialized = false;
	private initPromise: Promise<void> | null = null;
	private serviceStatus = {
		database: false,
		embedding: false,
		llm: false,
		flows: false,
		topic: false,
	};

	// Child services - initialized based on mode
	public embeddingService!: IEmbeddingService;
	public llmService!: ILLMService;
	public databaseService!: DatabaseService;
	public flowsService!: FlowsService;

	// Progress tracking
	private progressListeners = new Set<
		(progress: InitializationProgress) => void
	>();
	private currentProgress: InitializationProgress = {
		step: "Starting",
		progress: 0,
		isComplete: false,
	};

	private constructor() {}

	static getInstance(): ServiceManager {
		if (!ServiceManager.instance) {
			ServiceManager.instance = new ServiceManager();
		}
		return ServiceManager.instance;
	}

	// Progress tracking methods
	onProgressChange(
		listener: (progress: InitializationProgress) => void,
	): () => void {
		this.progressListeners.add(listener);
		// Send current progress immediately
		listener(this.currentProgress);
		return () => this.progressListeners.delete(listener);
	}

	private updateProgress(
		step: string,
		progress: number,
		currentService?: string,
	): void {
		this.currentProgress = {
			step,
			progress,
			currentService,
			isComplete: progress >= 100,
		};
		this.progressListeners.forEach((listener) =>
			listener(this.currentProgress),
		);
	}

	getCurrentProgress(): InitializationProgress {
		return { ...this.currentProgress };
	}

	async initialize(
		options: {
			proxy?: boolean;
			callback?: (service: string, progress: number) => void;
		} = {
			proxy: false,
			callback: undefined,
		},
	): Promise<void> {
		if (this.initialized) return;
		if (this.initPromise) return this.initPromise;

		this.initPromise = this.initializeServices(options);
		await this.initPromise;
		this.initialized = true;
	}

	private async initializeServices(
		options: {
			proxy?: boolean;
			callback?: (service: string, progress: number) => void;
		} = {
			proxy: false,
			callback: undefined,
		},
	): Promise<void> {
		const mode = options.proxy ? "proxy mode" : "full mode";
		logInfo(`üöÄ Initializing services in ${mode}...`);
		this.updateProgress(`Initializing services (${mode})`, 5);

		try {
			// Create service instances based on mode
			if (options.proxy) {
				logInfo("üîß Creating lite service implementations");
				this.databaseService = DatabaseService.getInstance();
				await this.initializeDatabase({ mode: DatabaseMode.PROXY });
				this.embeddingService = new EmbeddingServiceProxy();
				this.llmService = new LLMServiceProxy();
				this.flowsService = new FlowsService();
			} else {
				logInfo("üîß Creating full service implementations");
				this.databaseService = DatabaseService.getInstance();
				await this.initializeDatabase({ mode: DatabaseMode.MAIN });
				this.embeddingService = new EmbeddingServiceMain();
				this.llmService = new LLMServiceMain();
				this.flowsService = new FlowsService();
			}

			options.callback?.("database", 0);
			// Initialize services sequentially for better progress tracking

			options.callback?.("database", 100);
			this.updateProgress("Database ready", 25, "database");

			if (options.proxy) {
				// Lite mode: Initialize services without heavy operations
				await this.initializeEmbeddingService(true);
				this.updateProgress("Embedding service ready (lite)", 50, "embedding");

				await this.initializeLLMService(true);
				this.updateProgress("LLM service ready (lite)", 75, "llm");
			} else {
				// Full mode: Initialize all services normally
				options.callback?.("embedding", 0);
				await this.initializeEmbeddingService(false);
				options.callback?.("embedding", 100);
				this.updateProgress("Embedding models loaded", 50, "embedding");

				options.callback?.("llm", 0);
				await this.initializeLLMService(false);
				options.callback?.("llm", 100);
				this.updateProgress("LLM service ready", 75, "llm");
			}

			options.callback?.("flow", 0);
			await this.initializeFlowsService();

			this.updateProgress("All services ready", 100, "flows");

			logInfo(`‚úÖ All services initialized successfully in ${mode}`);
		} catch (error) {
			logError("‚ùå Failed to initialize services:", error);
			this.updateProgress("All services ready", 100, "flows");
			throw error;
		}
	}

	private async initializeDatabase(options: {
		mode: DatabaseMode;
	}): Promise<void> {
		try {
			logInfo("üìö Initializing database...");
			this.updateProgress(
				"Setting up knowledge graph database",
				10,
				"database",
			);
			await this.databaseService.initialize(options);
			this.serviceStatus.database = true;
			logInfo("‚úÖ Database initialized");
		} catch (error) {
			logError("‚ùå Database initialization failed:", error);
			throw new Error(
				`Database initialization failed: ${error instanceof Error ? error.message : "Unknown error"}`,
			);
		}
	}

	private async initializeEmbeddingService(
		liteMode: boolean = false,
	): Promise<void> {
		try {
			logInfo(
				`üî§ Initializing embedding service${liteMode ? " (lite mode)" : ""}...`,
			);
			this.updateProgress(
				liteMode
					? "Setting up embedding service proxy"
					: "Loading embedding models for semantic search",
				35,
				"embedding",
			);

			await this.embeddingService.initialize();

			if (!liteMode) {
				// Full mode: Create default embedding model
				await this.embeddingService.create("default", "local", {
					type: "local",
					modelName: "nomic-ai/nomic-embed-text-v1.5",
				});
				logInfo("‚úÖ Embedding service initialized with local models");
			} else {
				logInfo(
					"‚úÖ Embedding service initialized in lite mode (will use offscreen for operations)",
				);
			}

			this.serviceStatus.embedding = true;
		} catch (error) {
			logError("‚ùå Embedding service initialization failed:", error);
			this.serviceStatus.embedding = false;
			// Don't throw - embedding service failure shouldn't block the app
			logWarn("‚ö†Ô∏è Continuing without embedding service");
			logError("Full error details:", error);
		}
	}

	private async initializeLLMService(liteMode: boolean = false): Promise<void> {
		try {
			logInfo(
				`ü¶ô Initializing LLM service${liteMode ? " (lite mode)" : ""}...`,
			);
			this.updateProgress(
				liteMode
					? "Setting up LLM service proxy"
					: "Initializing local LLM inference service",
				60,
				"llm",
			);

			await this.llmService.initialize();

			if (liteMode) {
				logInfo(
					"‚úÖ LLM service initialized in lite mode (will use offscreen for heavy operations)",
				);
			} else {
				logInfo("‚úÖ LLM service initialized with local models");
			}

			this.serviceStatus.llm = true;
		} catch (error) {
			logError("‚ùå LLM service initialization failed:", error);
			this.serviceStatus.llm = false;
			// Don't throw - LLM service failure shouldn't block the app
			logWarn("‚ö†Ô∏è Continuing without LLM service");
		}
	}

	private async initializeFlowsService(): Promise<void> {
		try {
			logInfo("üîÑ Initializing Flows service...");
			this.updateProgress(
				"Preparing chat interface and model management",
				90,
				"flows",
			);
			await this.flowsService.initialize();
			this.serviceStatus.flows = true;
			logInfo("‚úÖ Flows service initialized");
		} catch (error) {
			logError("‚ùå Flows service initialization failed:", error);
			this.serviceStatus.flows = false;
			// Don't throw - Flows service failure shouldn't block the app
			logWarn("‚ö†Ô∏è Continuing without Flows service");
		}
	}

	isInitialized(): boolean {
		return this.initialized;
	}

	// Check individual service status
	async isEmbeddingServiceReady(): Promise<boolean> {
		if (!this.embeddingService) return false;
		const embedding = await this.embeddingService.get("default");
		return this.serviceStatus.embedding && embedding
			? embedding.isReady()
			: false;
	}

	isLLMServiceReady(): boolean {
		return (
			this.serviceStatus.llm && this.llmService && this.llmService.isReady()
		);
	}

	isDatabaseReady(): boolean {
		return this.serviceStatus.database && this.databaseService.isReady();
	}

	isFlowsServiceReady(): boolean {
		return this.serviceStatus.flows;
	}

	// Get overall service status
	getServiceStatus() {
		return {
			...this.serviceStatus,
			overall: this.initialized,
		};
	}

	// Service getters for easy access
	getEmbeddingService() {
		return this.embeddingService;
	}

	getLLMService() {
		return this.llmService;
	}

	getDatabaseService() {
		return this.databaseService;
	}

	getFlowsService() {
		return this.flowsService;
	}

	// Generic service getter for dynamic access
	getService<K extends keyof ServiceRegistry>(
		serviceName: K,
	): ServiceRegistry[K] | undefined {
		switch (serviceName) {
			case "database":
				return this.databaseService as ServiceRegistry[K];
			case "embedding":
				return this.embeddingService as ServiceRegistry[K];
			case "llm":
				return this.llmService as ServiceRegistry[K];
			case "flows":
				return this.flowsService as ServiceRegistry[K];
			default:
				return undefined;
		}
	}
}

// Service registry for type-safe service access
interface ServiceRegistry {
	database: DatabaseService;
	embedding: IEmbeddingService;
	llm: ILLMService;
	flows: FlowsService;
}
